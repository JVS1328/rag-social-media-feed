{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvEX8qLv1ahq"
      },
      "source": [
        "# RAG-based Social Media Feed Generator for Fictional Universes\n",
        "\n",
        "### John Skorcik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FS-rquGFwGST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7110f1d2-810a-40e9-f828-1a34fb8be97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m360.3/360.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.58)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.23 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain llama-cpp-python faiss-cpu sentence-transformers tqdm pydantic transformers accelerate networkx pyvis neo4j\n",
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5CIFHGa1RQl",
        "outputId": "f38b8ff0-3e08-4bdb-be5d-e373eb374fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries and Componenets successfully imported.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import List, Dict, Any, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from IPython.display import HTML, display, IFrame\n",
        "\n",
        "# RAG Components\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "\n",
        "\n",
        "print(\"Libraries and Componenets successfully imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWu4AOef1jmf"
      },
      "outputs": [],
      "source": [
        "# Set up a smaller open-source model using Hugging Face's models\n",
        "def setup_huggingface_pipeline():\n",
        "    \"\"\"Set up a Hugging Face pipeline for text generation using a smaller model\"\"\"\n",
        "    print(\"Loading model - this might take a minute...\")\n",
        "\n",
        "    # Using a smaller but capable model like Phi-2\n",
        "    model_id = \"microsoft/phi-2\"  # alternatively, we could use \"google/gemma-2b-it\" or \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # Create a text generation pipeline\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=1024,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        #do_sample=True,\n",
        "        repetition_penalty=1.05\n",
        "    )\n",
        "\n",
        "    # Create the LangChain wrapper\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    print(\"Model loaded successfully!\")\n",
        "    return llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtGAvj-9vGHN"
      },
      "source": [
        "### Define social media post data models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzU3n9kY3vMJ"
      },
      "outputs": [],
      "source": [
        "class UserProfile(BaseModel):\n",
        "    id: str\n",
        "    name: str\n",
        "    username: str\n",
        "    bio: Optional[str] = None\n",
        "    avatar_emoji: str = \"ğŸ‘¤\"  # Using emoji as avatar placeholder\n",
        "    followers: int = Field(default_factory=lambda: random.randint(50, 10000))\n",
        "    following: int = Field(default_factory=lambda: random.randint(50, 500))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYyO0kbyvNMF"
      },
      "outputs": [],
      "source": [
        "class SocialMediaPost(BaseModel):\n",
        "    id: str\n",
        "    user: UserProfile\n",
        "    content: str\n",
        "    likes: int = Field(default_factory=lambda: random.randint(0, 1000))\n",
        "    shares: int = Field(default_factory=lambda: random.randint(0, 100))\n",
        "    comments: int = Field(default_factory=lambda: random.randint(0, 50))\n",
        "    timestamp: datetime = Field(default_factory=lambda: datetime.now() - timedelta(\n",
        "        hours=random.randint(0, 72)))\n",
        "    referenced_entities: List[str] = []\n",
        "\n",
        "    def format_time(self) -> str:\n",
        "        delta = datetime.now() - self.timestamp\n",
        "        if delta.days > 0:\n",
        "            return f\"{delta.days}d ago\"\n",
        "        elif delta.seconds // 3600 > 0:\n",
        "            return f\"{delta.seconds // 3600}h ago\"\n",
        "        else:\n",
        "            return f\"{delta.seconds // 60}m ago\"\n",
        "\n",
        "    def display_post(self):\n",
        "        \"\"\"Display the post in a social media-like format\"\"\"\n",
        "        html = f\"\"\"\n",
        "        <div style=\"border: 1px solid #ddd; border-radius: 8px; padding: 12px; margin-bottom: 16px; max-width: 500px; font-family: Arial, sans-serif;\">\n",
        "            <div style=\"display: flex; align-items: center; margin-bottom: 8px;\">\n",
        "                <div style=\"font-size: 32px; margin-right: 12px;\">{self.user.avatar_emoji}</div>\n",
        "                <div>\n",
        "                    <div style=\"font-weight: bold;\">{self.user.name}</div>\n",
        "                    <div style=\"color: #536471; font-size: 14px;\">@{self.user.username}</div>\n",
        "                </div>\n",
        "            </div>\n",
        "            <p style=\"margin: 12px 0; font-size: 15px; line-height: 1.4;\">{self.content}</p>\n",
        "            <div style=\"color: #536471; font-size: 14px; margin-top: 12px;\">{self.format_time()}</div>\n",
        "            <div style=\"display: flex; justify-content: space-between; color: #536471; font-size: 14px; margin-top: 12px;\">\n",
        "                <div>â¤ï¸ {self.likes}</div>\n",
        "                <div>ğŸ”„ {self.shares}</div>\n",
        "                <div>ğŸ’¬ {self.comments}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(html))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NG0GoVzvXxT"
      },
      "outputs": [],
      "source": [
        "class Entity(BaseModel):\n",
        "    \"\"\"Base class for all entities in the knowledge graph\"\"\"\n",
        "    id: str\n",
        "    name: str\n",
        "    type: str\n",
        "    description: str\n",
        "    attributes: Dict[str, Any] = Field(default_factory=dict)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.name} ({self.type})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt88y0K0vZub"
      },
      "outputs": [],
      "source": [
        "class Relationship(BaseModel):\n",
        "    \"\"\"Base class for relationships between entities\"\"\"\n",
        "    source_id: str\n",
        "    target_id: str\n",
        "    type: str\n",
        "    description: str\n",
        "    attributes: Dict[str, Any] = Field(default_factory=dict)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"{self.type}: {self.description}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtxNzERqvbmc"
      },
      "outputs": [],
      "source": [
        "class KnowledgeGraph:\n",
        "    \"\"\"Class to manage the knowledge graph for a fictional universe\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.entities = {}  # id -> Entity\n",
        "        self.relationships = []  # List of Relationship objects\n",
        "        self.graph = nx.DiGraph()  # NetworkX graph\n",
        "\n",
        "    def add_entity(self, entity: Entity):\n",
        "        \"\"\"Add an entity to the knowledge graph\"\"\"\n",
        "        self.entities[entity.id] = entity\n",
        "        self.graph.add_node(entity.id, **entity.model_dump())\n",
        "\n",
        "    def add_relationship(self, relationship: Relationship):\n",
        "        \"\"\"Add a relationship to the knowledge graph\"\"\"\n",
        "        self.relationships.append(relationship)\n",
        "        self.graph.add_edge(\n",
        "            relationship.source_id,\n",
        "            relationship.target_id,\n",
        "            type=relationship.type,\n",
        "            description=relationship.description,\n",
        "            **relationship.attributes\n",
        "        )\n",
        "\n",
        "    def get_entity_by_name(self, name: str) -> Optional[Entity]:\n",
        "        \"\"\"Find an entity by name (case-insensitive)\"\"\"\n",
        "        for entity in self.entities.values():\n",
        "            if entity.name.lower() == name.lower():\n",
        "                return entity\n",
        "        return None\n",
        "\n",
        "    def get_related_entities(self, entity_id: str) -> List[Dict]:\n",
        "        \"\"\"Get all entities related to the given entity\"\"\"\n",
        "        if entity_id not in self.graph:\n",
        "            return []\n",
        "\n",
        "        related = []\n",
        "        for neighbor in self.graph.neighbors(entity_id):\n",
        "            edge_data = self.graph.get_edge_data(entity_id, neighbor)\n",
        "            entity = self.entities[neighbor]\n",
        "            related.append({\n",
        "                \"entity\": entity,\n",
        "                \"relationship\": edge_data\n",
        "            })\n",
        "\n",
        "        # Also check incoming edges\n",
        "        for predecessor in self.graph.predecessors(entity_id):\n",
        "            if predecessor != entity_id:  # Skip self-loops\n",
        "                edge_data = self.graph.get_edge_data(predecessor, entity_id)\n",
        "                entity = self.entities[predecessor]\n",
        "                related.append({\n",
        "                    \"entity\": entity,\n",
        "                    \"relationship\": edge_data\n",
        "                })\n",
        "\n",
        "        return related\n",
        "\n",
        "    def get_subgraph_for_entity(self, entity_id: str, depth: int = 2) -> nx.DiGraph:\n",
        "        \"\"\"Get a subgraph centered on the given entity with a specified depth\"\"\"\n",
        "        if entity_id not in self.graph:\n",
        "            return nx.DiGraph()\n",
        "\n",
        "        # Find all nodes within \"depth\" steps of the entity\n",
        "        nodes = {entity_id}\n",
        "        current_layer = {entity_id}\n",
        "\n",
        "        for _ in range(depth):\n",
        "            next_layer = set()\n",
        "            for node in current_layer:\n",
        "                # Add outgoing neighbors\n",
        "                next_layer.update(self.graph.neighbors(node))\n",
        "                # Add incoming neighbors\n",
        "                next_layer.update(self.graph.predecessors(node))\n",
        "\n",
        "            nodes.update(next_layer)\n",
        "            current_layer = next_layer\n",
        "\n",
        "        # Create subgraph with these nodes\n",
        "        return self.graph.subgraph(nodes).copy()\n",
        "\n",
        "    def visualize(self, filename=\"knowledge_graph.html\", height=800):\n",
        "        \"\"\"Visualize the knowledge graph using pyvis\"\"\"\n",
        "        try:\n",
        "            from pyvis.network import Network\n",
        "\n",
        "            net = Network(height=f\"{height}px\", width=\"100%\", directed=True, notebook=True)\n",
        "\n",
        "            # Add nodes\n",
        "            for entity_id, entity in self.entities.items():\n",
        "                node_title = f\"{entity.name}: {entity.description}\"\n",
        "                node_color = self._get_color_for_entity_type(entity.type)\n",
        "                net.add_node(entity_id, label=entity.name, title=node_title, color=node_color)\n",
        "\n",
        "            # Add edges\n",
        "            for relationship in self.relationships:\n",
        "                edge_title = relationship.description\n",
        "                net.add_edge(relationship.source_id, relationship.target_id, title=edge_title, label=relationship.type)\n",
        "\n",
        "            # Save and display\n",
        "            net.save_graph(filename)\n",
        "            return IFrame(filename, width=\"100%\", height=height)\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"pyvis is required for visualization. Install with: pip install pyvis\")\n",
        "            return None\n",
        "\n",
        "    def _get_color_for_entity_type(self, entity_type: str) -> str:\n",
        "        \"\"\"Return a color based on entity type\"\"\"\n",
        "        color_map = {\n",
        "            \"Character\": \"#4285F4\",  # Blue\n",
        "            \"Location\": \"#34A853\",   # Green\n",
        "            \"Event\": \"#FBBC05\",      # Yellow\n",
        "            \"Item\": \"#EA4335\",       # Red\n",
        "            \"Organization\": \"#8E24AA\", # Purple\n",
        "            \"Concept\": \"#00ACC1\"     # Teal\n",
        "        }\n",
        "        return color_map.get(entity_type, \"#9E9E9E\")  # Default gray\n",
        "\n",
        "    def to_dict(self) -> Dict:\n",
        "        \"\"\"Convert the knowledge graph to a dictionary representation\"\"\"\n",
        "        return {\n",
        "            \"entities\": {id: entity.model_dump() for id, entity in self.entities.items()},\n",
        "            \"relationships\": [r.dict() for r in self.relationships]\n",
        "        }\n",
        "\n",
        "    def to_json(self, filename: str):\n",
        "        \"\"\"Save the knowledge graph to a JSON file\"\"\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.to_dict(), f, indent=2, default=str)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, data: Dict) -> 'KnowledgeGraph':\n",
        "        \"\"\"Create a knowledge graph from a dictionary representation\"\"\"\n",
        "        kg = cls()\n",
        "\n",
        "        for entity_id, entity_data in data[\"entities\"].items():\n",
        "            entity = Entity(**entity_data)\n",
        "            kg.add_entity(entity)\n",
        "\n",
        "        for relationship_data in data[\"relationships\"]:\n",
        "            relationship = Relationship(**relationship_data)\n",
        "            kg.add_relationship(relationship)\n",
        "\n",
        "        return kg\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, filename: str) -> 'KnowledgeGraph':\n",
        "        \"\"\"Load a knowledge graph from a JSON file\"\"\"\n",
        "        with open(filename, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        return cls.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WdX23aLvhfs"
      },
      "outputs": [],
      "source": [
        "class UniverseKG:\n",
        "    \"\"\"A class to manage fictional universe knowledge through a knowledge graph\"\"\"\n",
        "\n",
        "    def __init__(self, universe_name: str):\n",
        "        self.universe_name = universe_name\n",
        "        self.knowledge_graph = KnowledgeGraph()\n",
        "        self.vectorstore = None\n",
        "        self.embeddings = None\n",
        "        self.llm = None\n",
        "        self.universe_summary = \"\"\n",
        "        self.expansion_chain = None\n",
        "        self.entity_chain = None\n",
        "        self.relationship_chain = None\n",
        "\n",
        "        # Create a universe entity\n",
        "        universe_entity = Entity(\n",
        "            id=f\"universe_{self._generate_id()}\",\n",
        "            name=universe_name,\n",
        "            type=\"Universe\",\n",
        "            description=f\"The {universe_name} fictional universe\"\n",
        "        )\n",
        "        self.knowledge_graph.add_entity(universe_entity)\n",
        "        self.universe_id = universe_entity.id\n",
        "\n",
        "    def initialize_llm(self):\n",
        "        \"\"\"Initialize the LLM for knowledge graph operations\"\"\"\n",
        "        print(\"Initializing LLM...\")\n",
        "\n",
        "        self.llm = setup_huggingface_pipeline()\n",
        "\n",
        "        # Universe expansion prompt\n",
        "        expansion_template = \"\"\"<s>[INST] You are a knowledge graph expert for the fictional universe: {universe_name}.\n",
        "\n",
        "I need you to expand on the universe concept with creative and consistent worldbuilding details. Generate a rich and\n",
        "coherent description of this universe based on the name alone. Think about the core themes, setting, timeline, magic\n",
        "or technology systems, major factions, and overall atmosphere.\n",
        "\n",
        "Your description should be detailed, imaginative, and internally consistent. Make sure the universe you describe\n",
        "would work well for interactive storytelling and social media simulation.\n",
        "\n",
        "Current universe information:\n",
        "{universe_description}\n",
        "\n",
        "Please generate an expanded universe summary that adds depth and richness to this concept. [/INST]\"\"\"\n",
        "\n",
        "        expansion_prompt = PromptTemplate(\n",
        "            input_variables=[\"universe_name\", \"universe_description\"],\n",
        "            template=expansion_template\n",
        "        )\n",
        "\n",
        "        self.expansion_chain = LLMChain(llm=self.llm, prompt=expansion_prompt)\n",
        "\n",
        "        # Entity generation prompt\n",
        "        entity_template = \"\"\"<s>[INST] You are a knowledge graph expert for the fictional universe: {universe_name}.\n",
        "\n",
        "Based on the universe description below, generate detailed information for {num_entities} new {entity_type} entities\n",
        "that would exist in this universe. Make these entities interesting, diverse, and consistent with the universe lore.\n",
        "\n",
        "Universe description:\n",
        "{universe_description}\n",
        "\n",
        "For each entity, provide:\n",
        "1. A name\n",
        "2. A detailed description (2-3 sentences)\n",
        "3. Several key attributes or characteristics\n",
        "4. How this entity fits into the universe\n",
        "\n",
        "Current entities already in the universe:\n",
        "{existing_entities}\n",
        "\n",
        "Please generate these new entities in a creative but consistent way that adds depth to the universe.\n",
        "Do not regenerate existing entities. [/INST]\"\"\"\n",
        "\n",
        "        entity_prompt = PromptTemplate(\n",
        "            input_variables=[\"universe_name\", \"universe_description\", \"entity_type\", \"num_entities\", \"existing_entities\"],\n",
        "            template=entity_template\n",
        "        )\n",
        "\n",
        "        self.entity_chain = LLMChain(llm=self.llm, prompt=entity_prompt)\n",
        "\n",
        "        # Relationship generation prompt\n",
        "        relationship_template = \"\"\"<s>[INST] You are a knowledge graph expert for the fictional universe: {universe_name}.\n",
        "\n",
        "I need you to identify meaningful relationships between entities in this universe.\n",
        "Based on the universe description and the entities listed below, generate {num_relationships} realistic\n",
        "relationships between these entities.\n",
        "\n",
        "Universe description:\n",
        "{universe_description}\n",
        "\n",
        "Entities:\n",
        "{entity_list}\n",
        "\n",
        "For each relationship, specify:\n",
        "1. The source entity\n",
        "2. The target entity\n",
        "3. The type of relationship (e.g., \"FRIENDS_WITH\", \"ENEMY_OF\", \"LOCATED_IN\", \"MEMBER_OF\", \"CREATED\", etc.)\n",
        "4. A brief description of the relationship (1-2 sentences)\n",
        "\n",
        "Make sure the relationships are logical and consistent with what we know about the universe and these entities.\n",
        "For characters, think about their alliances, rivalries, family ties, and organizational affiliations.\n",
        "For locations, consider which entities might be located there or have special connections to these places.\n",
        "For events, think about which entities participated in or were affected by them.\n",
        "\n",
        "Please generate diverse and interesting relationships that enrich the universe's narrative. [/INST]\"\"\"\n",
        "\n",
        "        relationship_prompt = PromptTemplate(\n",
        "            input_variables=[\"universe_name\", \"universe_description\", \"entity_list\", \"num_relationships\"],\n",
        "            template=relationship_template\n",
        "        )\n",
        "\n",
        "        self.relationship_chain = LLMChain(llm=self.llm, prompt=relationship_prompt)\n",
        "\n",
        "        print(\"LLM initialized successfully!\")\n",
        "\n",
        "    def expand_universe(self):\n",
        "        \"\"\"Expand the universe description using the LLM\"\"\"\n",
        "        if not self.llm:\n",
        "            self.initialize_llm()\n",
        "\n",
        "        universe_entity = self.knowledge_graph.entities[self.universe_id]\n",
        "        current_description = universe_entity.description\n",
        "\n",
        "        print(\"Expanding universe concept...\")\n",
        "        expanded_description = self.expansion_chain.run(\n",
        "            universe_name=self.universe_name,\n",
        "            universe_description=current_description\n",
        "        )\n",
        "\n",
        "        # Update universe entity\n",
        "        universe_entity.description = expanded_description\n",
        "        self.universe_summary = expanded_description\n",
        "\n",
        "        # Update in knowledge graph\n",
        "        self.knowledge_graph.entities[self.universe_id] = universe_entity\n",
        "\n",
        "        return expanded_description\n",
        "\n",
        "    def generate_entities(self, entity_type: str, num_entities: int = 5):\n",
        "        \"\"\"Generate new entities for the universe\"\"\"\n",
        "        if not self.llm:\n",
        "            self.initialize_llm()\n",
        "\n",
        "        # Get existing entities of this type for context\n",
        "        existing_entities = \"\\n\".join([\n",
        "            f\"- {entity.name}: {entity.description}\"\n",
        "            for entity in self.knowledge_graph.entities.values()\n",
        "            if entity.type == entity_type\n",
        "        ])\n",
        "\n",
        "        if not self.universe_summary:\n",
        "            self.universe_summary = self.knowledge_graph.entities[self.universe_id].description\n",
        "\n",
        "        print(f\"Generating {num_entities} {entity_type} entities...\")\n",
        "\n",
        "        # More structured prompt to get consistent output\n",
        "        entity_template = \"\"\"\n",
        "        You are creating {num_entities} new {entity_type} entities for the fictional universe: {universe_name}.\n",
        "\n",
        "        Universe description:\n",
        "        {universe_description}\n",
        "\n",
        "        Existing {entity_type} entities:\n",
        "        {existing_entities}\n",
        "\n",
        "        Generate exactly {num_entities} new {entity_type} entities.\n",
        "\n",
        "        FORMAT YOUR RESPONSE EXACTLY AS FOLLOWS FOR EACH ENTITY:\n",
        "\n",
        "        ###ENTITY###\n",
        "        Name: [entity name]\n",
        "        Description: [brief description]\n",
        "        Attribute1: [value]\n",
        "        Attribute2: [value]\n",
        "        (add more attributes as appropriate)\n",
        "        ###END###\n",
        "\n",
        "        Make each entity interesting and fitting for the universe. Do not include any other text outside the specified format.\n",
        "        \"\"\"\n",
        "\n",
        "        generation_prompt = PromptTemplate(\n",
        "            input_variables=[\"universe_name\", \"universe_description\", \"entity_type\", \"num_entities\", \"existing_entities\"],\n",
        "            template=entity_template\n",
        "        )\n",
        "\n",
        "        entity_chain = LLMChain(llm=self.llm, prompt=generation_prompt)\n",
        "\n",
        "        generation_result = entity_chain.run(\n",
        "            universe_name=self.universe_name,\n",
        "            universe_description=self.universe_summary,\n",
        "            entity_type=entity_type,\n",
        "            num_entities=num_entities,\n",
        "            existing_entities=existing_entities\n",
        "        )\n",
        "\n",
        "        print(\"Raw generation result:\")\n",
        "        print(generation_result[:500] + \"...\" if len(generation_result) > 500 else generation_result)\n",
        "\n",
        "        # Process the result to extract entities using the ###ENTITY### markers\n",
        "        entities = []\n",
        "        entity_blocks = generation_result.split(\"###ENTITY###\")\n",
        "\n",
        "        for block in entity_blocks:\n",
        "            if \"###END###\" not in block:\n",
        "                continue\n",
        "\n",
        "            entity_text = block.split(\"###END###\")[0].strip()\n",
        "            if not entity_text:\n",
        "                continue\n",
        "\n",
        "            entity_data = {\"attributes\": {}}\n",
        "\n",
        "            # Parse the entity data\n",
        "            lines = entity_text.split('\\n')\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                if \":\" in line:\n",
        "                    key, value = line.split(\":\", 1)\n",
        "                    key = key.strip()\n",
        "                    value = value.strip()\n",
        "\n",
        "                    if key.lower() == \"name\":\n",
        "                        entity_data[\"name\"] = value\n",
        "                    elif key.lower() == \"description\":\n",
        "                        entity_data[\"description\"] = value\n",
        "                    else:\n",
        "                        # Everything else is an attribute\n",
        "                        entity_data[\"attributes\"][key] = value\n",
        "\n",
        "            if \"name\" in entity_data and \"description\" in entity_data:\n",
        "                entities.append(entity_data)\n",
        "\n",
        "        print(f\"Extracted {len(entities)} entities from the generation result\")\n",
        "\n",
        "        # Create and add entities to the knowledge graph\n",
        "        added_entities = []\n",
        "        for entity_data in entities:\n",
        "            entity = Entity(\n",
        "                id=f\"{entity_type.lower()}_{self._generate_id()}\",\n",
        "                name=entity_data[\"name\"],\n",
        "                type=entity_type,\n",
        "                description=entity_data[\"description\"],\n",
        "                attributes=entity_data.get(\"attributes\", {})\n",
        "            )\n",
        "\n",
        "            self.knowledge_graph.add_entity(entity)\n",
        "            added_entities.append(entity)\n",
        "\n",
        "            # Connect to universe\n",
        "            relationship = Relationship(\n",
        "                source_id=entity.id,\n",
        "                target_id=self.universe_id,\n",
        "                type=\"PART_OF\",\n",
        "                description=f\"{entity.name} is part of the {self.universe_name} universe\"\n",
        "            )\n",
        "            self.knowledge_graph.add_relationship(relationship)\n",
        "\n",
        "        print(f\"Added {len(added_entities)} {entity_type} entities to the universe\")\n",
        "        return added_entities\n",
        "\n",
        "    def generate_relationships(self, num_relationships: int = 10):\n",
        "        \"\"\"Generate relationships between existing entities\"\"\"\n",
        "        if not self.llm:\n",
        "            self.initialize_llm()\n",
        "\n",
        "        if len(self.knowledge_graph.entities) < 3:\n",
        "            print(\"Not enough entities to generate meaningful relationships\")\n",
        "            return []\n",
        "\n",
        "        # Prepare entity list for the prompt\n",
        "        entity_list = \"\\n\".join([\n",
        "            f\"- {entity.name} ({entity.type}): {entity.description}\"\n",
        "            for entity_id, entity in self.knowledge_graph.entities.items()\n",
        "            if entity_id != self.universe_id  # Exclude the universe itself\n",
        "        ])\n",
        "\n",
        "        if not self.universe_summary:\n",
        "            self.universe_summary = self.knowledge_graph.entities[self.universe_id].description\n",
        "\n",
        "        print(f\"Generating {num_relationships} relationships...\")\n",
        "        generation_result = self.relationship_chain.run(\n",
        "            universe_name=self.universe_name,\n",
        "            universe_description=self.universe_summary,\n",
        "            entity_list=entity_list,\n",
        "            num_relationships=num_relationships\n",
        "        )\n",
        "\n",
        "        # Process the result to extract relationships\n",
        "        # This is a simplified parsing logic - for production, use a more robust approach\n",
        "        relationships = []\n",
        "        lines = generation_result.strip().split('\\n')\n",
        "\n",
        "        current_relationship = {}\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # New relationship starts with a number\n",
        "            if line[0].isdigit() or line.startswith(\"-\"):\n",
        "                # Save previous relationship if it exists\n",
        "                if current_relationship.get(\"source\") and current_relationship.get(\"target\"):\n",
        "                    relationships.append(current_relationship)\n",
        "                    current_relationship = {}\n",
        "\n",
        "                # This might be the beginning of a new relationship\n",
        "                continue\n",
        "\n",
        "            # Source entity\n",
        "            if line.startswith(\"Source:\") or line.startswith(\"From:\"):\n",
        "                current_relationship[\"source\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "            # Target entity\n",
        "            elif line.startswith(\"Target:\") or line.startswith(\"To:\"):\n",
        "                current_relationship[\"target\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "            # Relationship type\n",
        "            elif line.startswith(\"Type:\") or line.startswith(\"Relationship:\"):\n",
        "                current_relationship[\"type\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "            # Description\n",
        "            elif line.startswith(\"Description:\"):\n",
        "                current_relationship[\"description\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "        # Add the last relationship\n",
        "        if current_relationship.get(\"source\") and current_relationship.get(\"target\"):\n",
        "            relationships.append(current_relationship)\n",
        "\n",
        "        # Create and add relationships to the knowledge graph\n",
        "        added_relationships = []\n",
        "        for rel_data in relationships:\n",
        "            if not all(k in rel_data for k in [\"source\", \"target\", \"type\", \"description\"]):\n",
        "                continue  # Skip incomplete relationships\n",
        "\n",
        "            # Find the entity IDs\n",
        "            source_entity = self.knowledge_graph.get_entity_by_name(rel_data[\"source\"])\n",
        "            target_entity = self.knowledge_graph.get_entity_by_name(rel_data[\"target\"])\n",
        "\n",
        "            if not source_entity or not target_entity:\n",
        "                continue  # Skip if entities not found\n",
        "\n",
        "            relationship = Relationship(\n",
        "                source_id=source_entity.id,\n",
        "                target_id=target_entity.id,\n",
        "                type=rel_data[\"type\"].upper().replace(\" \", \"_\"),\n",
        "                description=rel_data[\"description\"]\n",
        "            )\n",
        "\n",
        "            self.knowledge_graph.add_relationship(relationship)\n",
        "            added_relationships.append(relationship)\n",
        "\n",
        "        print(f\"Added {len(added_relationships)} relationships to the universe\")\n",
        "        return added_relationships\n",
        "\n",
        "    def initialize_embeddings(self):\n",
        "        \"\"\"Initialize the embeddings for vector search\"\"\"\n",
        "        print(\"Initializing embeddings...\")\n",
        "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        print(\"Embeddings initialized successfully!\")\n",
        "\n",
        "    def build_vectorstore(self):\n",
        "        \"\"\"Build a vector store from knowledge graph entities and relationships\"\"\"\n",
        "        if not self.embeddings:\n",
        "            self.initialize_embeddings()\n",
        "\n",
        "        print(\"Building vector store...\")\n",
        "\n",
        "        # Prepare documents\n",
        "        docs = []\n",
        "\n",
        "        # Add entity documents\n",
        "        for entity_id, entity in self.knowledge_graph.entities.items():\n",
        "            doc_text = f\"Name: {entity.name}\\nType: {entity.type}\\nDescription: {entity.description}\\n\"\n",
        "\n",
        "            # Add attributes\n",
        "            if entity.attributes:\n",
        "                doc_text += \"Attributes:\\n\"\n",
        "                for key, value in entity.attributes.items():\n",
        "                    doc_text += f\"- {key}: {value}\\n\"\n",
        "\n",
        "            docs.append(doc_text)\n",
        "\n",
        "        # Add relationship documents\n",
        "        for relationship in self.knowledge_graph.relationships:\n",
        "            source_entity = self.knowledge_graph.entities[relationship.source_id]\n",
        "            target_entity = self.knowledge_graph.entities[relationship.target_id]\n",
        "\n",
        "            doc_text = f\"Relationship: {source_entity.name} {relationship.type} {target_entity.name}\\n\"\n",
        "            doc_text += f\"Description: {relationship.description}\\n\"\n",
        "\n",
        "            docs.append(doc_text)\n",
        "\n",
        "        # Create vector store\n",
        "        self.vectorstore = FAISS.from_texts(docs, self.embeddings)\n",
        "\n",
        "        print(f\"Vector store built successfully with {len(docs)} documents\")\n",
        "        return self.vectorstore\n",
        "\n",
        "    def get_entity_context(self, entity_name: str, max_depth: int = 2) -> str:\n",
        "        \"\"\"Get context information about an entity and its relationships\"\"\"\n",
        "        entity = self.knowledge_graph.get_entity_by_name(entity_name)\n",
        "        if not entity:\n",
        "            return f\"No information found about {entity_name}\"\n",
        "\n",
        "        context = f\"Entity: {entity.name} ({entity.type})\\n\"\n",
        "        context += f\"Description: {entity.description}\\n\\n\"\n",
        "\n",
        "        # Add attributes\n",
        "        if entity.attributes:\n",
        "            context += \"Attributes:\\n\"\n",
        "            for key, value in entity.attributes.items():\n",
        "                context += f\"- {key}: {value}\\n\"\n",
        "            context += \"\\n\"\n",
        "\n",
        "        # Add relationships\n",
        "        related = self.knowledge_graph.get_related_entities(entity.id)\n",
        "        if related:\n",
        "            context += \"Relationships:\\n\"\n",
        "            for rel in related:\n",
        "                related_entity = rel[\"entity\"]\n",
        "                relationship = rel[\"relationship\"]\n",
        "                context += f\"- {relationship['type']}: {related_entity.name} - {relationship['description']}\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def retrieve_related_context(self, query: str, k: int = 3) -> str:\n",
        "        \"\"\"Retrieve context information relevant to a query\"\"\"\n",
        "        if not self.vectorstore:\n",
        "            self.build_vectorstore()\n",
        "\n",
        "        docs = self.vectorstore.similarity_search(query, k=k)\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "        return context\n",
        "\n",
        "    def _generate_id(self) -> str:\n",
        "        \"\"\"Generate a random ID string\"\"\"\n",
        "        return ''.join(random.choices('abcdefghijklmnopqrstuvwxyz0123456789', k=8))\n",
        "\n",
        "    def auto_populate(self, num_characters=5, num_locations=3, num_events=2, num_items=2, num_relationships=15):\n",
        "        \"\"\"Automatically populate the universe with various entity types and relationships\"\"\"\n",
        "        if not self.llm:\n",
        "            self.initialize_llm()\n",
        "\n",
        "        # First, expand the universe concept\n",
        "        self.expand_universe()\n",
        "\n",
        "        # Generate entities\n",
        "        print(f\"Attempting to generate {num_characters} characters...\")\n",
        "        if num_characters > 0:\n",
        "            characters = self.generate_entities(\"Character\", num_characters)\n",
        "            print(f\"Generated {len(characters)} characters: {[c.name for c in characters]}\")\n",
        "\n",
        "        if num_locations > 0:\n",
        "            self.generate_entities(\"Location\", num_locations)\n",
        "\n",
        "        if num_events > 0:\n",
        "            self.generate_entities(\"Event\", num_events)\n",
        "\n",
        "        if num_items > 0:\n",
        "            self.generate_entities(\"Item\", num_items)\n",
        "\n",
        "        # Generate relationships\n",
        "        if num_relationships > 0:\n",
        "            self.generate_relationships(num_relationships)\n",
        "\n",
        "        # Initialize vector store\n",
        "        self.build_vectorstore()\n",
        "\n",
        "        print(f\"Universe '{self.universe_name}' auto-populated successfully!\")\n",
        "        return self.knowledge_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnEG2_qXvoiD"
      },
      "outputs": [],
      "source": [
        "class FeedGenerator:\n",
        "    \"\"\"Generator for social media feeds based on fictional universes with KG-based RAG\"\"\"\n",
        "\n",
        "    def __init__(self, universe_kg: UniverseKG):\n",
        "        self.universe = universe_kg\n",
        "        self.llm = None\n",
        "        self.post_chain = None\n",
        "        self.initialize_llm()\n",
        "\n",
        "    def initialize_llm(self):\n",
        "        \"\"\"Initialize the LLM and chain for generating posts\"\"\"\n",
        "        print(\"Initializing LLM...\")\n",
        "\n",
        "        self.llm = setup_huggingface_pipeline()\n",
        "\n",
        "        # Create prompt template for generating posts\n",
        "        post_template = \"\"\"<s>[INST] You are a social media post generator for characters in a fictional universe.\n",
        "\n",
        "Universe Information:\n",
        "{universe_description}\n",
        "\n",
        "Character Information:\n",
        "Name: {character_name}\n",
        "Description: {character_description}\n",
        "\n",
        "Additional Context:\n",
        "{context}\n",
        "\n",
        "Based on this information and context, generate a realistic social media post that this character would make.\n",
        "The post should reference universe-specific knowledge, other characters, locations, events, or items in a natural way.\n",
        "Make the post authentic to how people post on social media. Avoid hashtags unless they're being used ironically.\n",
        "Keep the post between 1-3 short paragraphs maximum.\n",
        "\n",
        "Ensure the tone, vocabulary, and content align with the character's personality and role in the universe.\n",
        "The post should feel like something written spontaneously, not a carefully crafted narrative.\n",
        "\n",
        "After generating the post, please list any specific entities (characters, locations, events, items, etc.) that were\n",
        "referenced in the post. Format as a simple comma-separated list. [/INST]\"\"\"\n",
        "\n",
        "        post_prompt = PromptTemplate(\n",
        "            input_variables=[\"universe_description\", \"character_name\", \"character_description\", \"context\"],\n",
        "            template=post_template\n",
        "        )\n",
        "\n",
        "        self.post_chain = LLMChain(llm=self.llm, prompt=post_prompt)\n",
        "        print(\"LLM initialized successfully!\")\n",
        "\n",
        "    def generate_character_username(self, character_name: str) -> str:\n",
        "        \"\"\"Generate a plausible username for a character\"\"\"\n",
        "        name_parts = character_name.lower().split()\n",
        "\n",
        "        # Generate different username styles\n",
        "        if random.random() < 0.3 and len(name_parts) > 1:\n",
        "            # First initial + last name\n",
        "            username = f\"{name_parts[0][0]}{name_parts[-1]}\"\n",
        "        elif random.random() < 0.5:\n",
        "            # Full name with random number\n",
        "            username = f\"{name_parts[0]}{name_parts[-1] if len(name_parts) > 1 else ''}{random.randint(1, 99)}\"\n",
        "        else:\n",
        "            # Some variation of the name\n",
        "            if len(name_parts) > 1:\n",
        "                username = f\"the_real_{name_parts[-1]}\"\n",
        "            else:\n",
        "                username = f\"{name_parts[0]}_official\"\n",
        "\n",
        "        # Remove spaces and special characters\n",
        "        username = ''.join(c for c in username if c.isalnum() or c == '_').lower()\n",
        "\n",
        "        return username\n",
        "\n",
        "    def generate_post(self, character_id: Optional[str] = None) -> SocialMediaPost:\n",
        "        \"\"\"Generate a social media post from a random or specified character\"\"\"\n",
        "        # Select a character\n",
        "        if character_id and character_id in self.universe.knowledge_graph.entities:\n",
        "            character = self.universe.knowledge_graph.entities[character_id]\n",
        "        else:\n",
        "            # Get a random character\n",
        "            characters = [\n",
        "                entity for entity_id, entity in self.universe.knowledge_graph.entities.items()\n",
        "                if entity.type == \"Character\"\n",
        "            ]\n",
        "            if not characters:\n",
        "                raise ValueError(\"No characters in universe\")\n",
        "            character = random.choice(characters)\n",
        "\n",
        "        # Get context about this character\n",
        "        context = self.universe.get_entity_context(character.name)\n",
        "\n",
        "        # Generate post content\n",
        "        universe_description = self.universe.universe_summary or self.universe.knowledge_graph.entities[self.universe.universe_id].description\n",
        "\n",
        "        post_result = self.post_chain.run(\n",
        "            universe_description=universe_description,\n",
        "            character_name=character.name,\n",
        "            character_description=character.description,\n",
        "            context=context\n",
        "        )\n",
        "\n",
        "        # Process the result to extract the post content and referenced entities\n",
        "        parts = post_result.strip().split(\"\\n\\n\")\n",
        "\n",
        "        # The post content is everything except the last part (which contains the entity list)\n",
        "        post_content = \"\\n\\n\".join(parts[:-1]) if len(parts) > 1 else post_result\n",
        "\n",
        "        # Extract referenced entities if available\n",
        "        referenced_entities = []\n",
        "        if len(parts) > 1 and \":\" in parts[-1]:\n",
        "            entity_list = parts[-1].split(\":\", 1)[1].strip()\n",
        "            referenced_entities = [entity.strip() for entity in entity_list.split(\",\")]\n",
        "\n",
        "        # Create user profile for the character\n",
        "        profile = UserProfile(\n",
        "            id=character.id,\n",
        "            name=character.name,\n",
        "            username=self.generate_character_username(character.name),\n",
        "            bio=character.description[:100] + \"...\" if len(character.description) > 100 else character.description,\n",
        "            avatar_emoji=random.choice([\"ğŸ‘©\", \"ğŸ‘¨\", \"ğŸ§™\", \"ğŸ‘¸\", \"ğŸ¤´\", \"ğŸ‘©â€ğŸš€\", \"ğŸ‘¨â€ğŸš€\", \"ğŸ§â€â™€ï¸\", \"ğŸ§\", \"ğŸ§›\", \"ğŸ¦¸\", \"ğŸ¦¹\"])\n",
        "        )\n",
        "\n",
        "        # Create the post\n",
        "        post = SocialMediaPost(\n",
        "            id=f\"post_{random.randint(10000, 99999)}\",\n",
        "            user=profile,\n",
        "            content=post_content.strip(),\n",
        "            referenced_entities=referenced_entities\n",
        "        )\n",
        "\n",
        "        return post\n",
        "\n",
        "    def generate_feed(self, num_posts: int = 5) -> List[SocialMediaPost]:\n",
        "        \"\"\"Generate a feed with multiple posts from different characters\"\"\"\n",
        "        feed = []\n",
        "\n",
        "        # Get all characters\n",
        "        characters = [\n",
        "            entity_id for entity_id, entity in self.universe.knowledge_graph.entities.items()\n",
        "            if entity.type == \"Character\"\n",
        "        ]\n",
        "\n",
        "        if not characters:\n",
        "            raise ValueError(\"No characters in universe\")\n",
        "\n",
        "        # Make sure we have enough characters\n",
        "        num_chars = min(num_posts, len(characters))\n",
        "\n",
        "        # Select random characters (no duplicates)\n",
        "        if num_chars < len(characters):\n",
        "            selected_chars = random.sample(characters, num_chars)\n",
        "        else:\n",
        "            selected_chars = characters.copy()\n",
        "            # Fill remaining with random selections (may have duplicates)\n",
        "            for _ in range(num_posts - num_chars):\n",
        "                selected_chars.append(random.choice(characters))\n",
        "\n",
        "        # Generate posts from selected characters\n",
        "        for char_id in tqdm(selected_chars, desc=\"Generating posts\"):\n",
        "            post = self.generate_post(char_id)\n",
        "            feed.append(post)\n",
        "\n",
        "        # Sort by timestamp to create chronological feed\n",
        "        feed.sort(key=lambda x: x.timestamp)\n",
        "\n",
        "        return feed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHS_5bKHvr26"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tQeoj9ovrjL"
      },
      "outputs": [],
      "source": [
        "# Demo function to create a universe from just a name\n",
        "def create_universe_from_name(universe_name: str, auto_populate: bool = True):\n",
        "    \"\"\"Create a universe from just a name using the LLM to expand it\"\"\"\n",
        "    universe = UniverseKG(universe_name)\n",
        "\n",
        "    # Initialize the LLM\n",
        "    universe.initialize_llm()\n",
        "\n",
        "    if auto_populate:\n",
        "        # Auto-populate the universe\n",
        "        universe.auto_populate(\n",
        "            num_characters=6,\n",
        "            num_locations=4,\n",
        "            num_events=3,\n",
        "            num_items=3,\n",
        "            num_relationships=20\n",
        "        )\n",
        "    else:\n",
        "        # Just expand the universe description\n",
        "        universe.expand_universe()\n",
        "\n",
        "    return universe\n",
        "\n",
        "# Function to visualize knowledge graph\n",
        "def visualize_universe(universe: UniverseKG):\n",
        "    \"\"\"Visualize the universe knowledge graph\"\"\"\n",
        "    return universe.knowledge_graph.visualize()\n",
        "\n",
        "# Demo function to generate a feed\n",
        "def generate_demo_feed(universe: UniverseKG, num_posts: int = 8):\n",
        "    \"\"\"Generate a social media feed for the given universe\"\"\"\n",
        "    generator = FeedGenerator(universe)\n",
        "    feed = generator.generate_feed(num_posts)\n",
        "\n",
        "    print(f\"\\n==== Social Media Feed from {universe.universe_name} ====\\n\")\n",
        "    for post in feed:\n",
        "        post.display_post()\n",
        "        if post.referenced_entities:\n",
        "            print(f\"Referenced entities: {', '.join(post.referenced_entities)}\")\n",
        "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "    return feed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFbEBwOgvwur"
      },
      "source": [
        "### UI for creating a universe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bASo2uzvyfi"
      },
      "outputs": [],
      "source": [
        "def create_universe_ui():\n",
        "    \"\"\"Create a user interface for creating and exploring universes\"\"\"\n",
        "    try:\n",
        "        import ipywidgets as widgets\n",
        "        from IPython.display import display, clear_output\n",
        "\n",
        "        # Main universe object\n",
        "        universe = None\n",
        "\n",
        "        # Create universe UI\n",
        "        universe_name_input = widgets.Text(description=\"Universe Name:\", placeholder=\"Enter a name for your universe\")\n",
        "\n",
        "        auto_populate_checkbox = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Auto-populate universe',\n",
        "            disabled=False\n",
        "        )\n",
        "\n",
        "        # Entity count sliders\n",
        "        char_slider = widgets.IntSlider(value=6, min=0, max=15, step=1, description='Characters:')\n",
        "        loc_slider = widgets.IntSlider(value=4, min=0, max=10, step=1, description='Locations:')\n",
        "        event_slider = widgets.IntSlider(value=3, min=0, max=8, step=1, description='Events:')\n",
        "        item_slider = widgets.IntSlider(value=3, min=0, max=8, step=1, description='Items:')\n",
        "        rel_slider = widgets.IntSlider(value=20, min=0, max=50, step=5, description='Relationships:')\n",
        "\n",
        "        entity_sliders = widgets.VBox([char_slider, loc_slider, event_slider, item_slider, rel_slider])\n",
        "\n",
        "        # Create button\n",
        "        create_btn = widgets.Button(description=\"Create Universe\")\n",
        "        create_output = widgets.Output()\n",
        "\n",
        "        # Feed generation\n",
        "        feed_slider = widgets.IntSlider(value=5, min=1, max=20, description='# Posts:')\n",
        "        generate_feed_btn = widgets.Button(description=\"Generate Feed\")\n",
        "        feed_output = widgets.Output()\n",
        "\n",
        "        # Visualization\n",
        "        visualize_btn = widgets.Button(description=\"Visualize Knowledge Graph\")\n",
        "        visualize_output = widgets.Output()\n",
        "\n",
        "        # Handle auto-populate checkbox\n",
        "        def on_auto_populate_change(change):\n",
        "            if change['new']:\n",
        "                entity_sliders.layout.display = ''\n",
        "            else:\n",
        "                entity_sliders.layout.display = 'none'\n",
        "\n",
        "        auto_populate_checkbox.observe(on_auto_populate_change, names='value')\n",
        "\n",
        "        # Create universe function\n",
        "        def on_create_click(b):\n",
        "            with create_output:\n",
        "                clear_output()\n",
        "                if not universe_name_input.value:\n",
        "                    print(\"Please enter a universe name\")\n",
        "                    return\n",
        "\n",
        "                print(f\"Creating universe: {universe_name_input.value}\")\n",
        "\n",
        "                nonlocal universe\n",
        "                universe = UniverseKG(universe_name_input.value)\n",
        "                universe.initialize_llm()\n",
        "\n",
        "                if auto_populate_checkbox.value:\n",
        "                    universe.auto_populate(\n",
        "                        num_characters=char_slider.value,\n",
        "                        num_locations=loc_slider.value,\n",
        "                        num_events=event_slider.value,\n",
        "                        num_items=item_slider.value,\n",
        "                        num_relationships=rel_slider.value\n",
        "                    )\n",
        "                else:\n",
        "                    universe.expand_universe()\n",
        "\n",
        "                print(f\"\\nUniverse '{universe.universe_name}' created successfully!\")\n",
        "                print(f\"\\nUniverse description:\\n{universe.universe_summary}\")\n",
        "\n",
        "        create_btn.on_click(on_create_click)\n",
        "\n",
        "        # Generate feed function\n",
        "        def on_generate_feed_click(b):\n",
        "            with feed_output:\n",
        "                clear_output()\n",
        "                if universe is None:\n",
        "                    print(\"Please create a universe first\")\n",
        "                    return\n",
        "\n",
        "                print(f\"Generating social media feed for {universe.universe_name}...\")\n",
        "                generator = FeedGenerator(universe)\n",
        "                feed = generator.generate_feed(feed_slider.value)\n",
        "\n",
        "                print(f\"\\n==== Social Media Feed from {universe.universe_name} ====\\n\")\n",
        "                for post in feed:\n",
        "                    post.display_post()\n",
        "                    if post.referenced_entities:\n",
        "                        print(f\"Referenced entities: {', '.join(post.referenced_entities)}\")\n",
        "                    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "        generate_feed_btn.on_click(on_generate_feed_click)\n",
        "\n",
        "        # Visualize function\n",
        "        def on_visualize_click(b):\n",
        "            with visualize_output:\n",
        "                clear_output()\n",
        "                if universe is None:\n",
        "                    print(\"Please create a universe first\")\n",
        "                    return\n",
        "\n",
        "                print(f\"Visualizing knowledge graph for {universe.universe_name}...\")\n",
        "                display(universe.knowledge_graph.visualize())\n",
        "\n",
        "        visualize_btn.on_click(on_visualize_click)\n",
        "\n",
        "        # Create widgets\n",
        "        create_widget = widgets.VBox([\n",
        "            universe_name_input,\n",
        "            auto_populate_checkbox,\n",
        "            entity_sliders,\n",
        "            create_btn,\n",
        "            create_output\n",
        "        ])\n",
        "\n",
        "        feed_widget = widgets.VBox([\n",
        "            feed_slider,\n",
        "            generate_feed_btn,\n",
        "            feed_output\n",
        "        ])\n",
        "\n",
        "        vis_widget = widgets.VBox([\n",
        "            visualize_btn,\n",
        "            visualize_output\n",
        "        ])\n",
        "\n",
        "        # Create tabs\n",
        "        tab = widgets.Tab()\n",
        "        tab.children = [create_widget, feed_widget, vis_widget]\n",
        "        tab.set_title(0, 'Create Universe')\n",
        "        tab.set_title(1, 'Generate Feed')\n",
        "        tab.set_title(2, 'Visualize')\n",
        "\n",
        "        display(tab)\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ipywidgets is required for the UI. Install with: pip install ipywidgets\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdNrdCLEv1j6"
      },
      "source": [
        "### Example universes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzDA9v1Rv28S"
      },
      "outputs": [],
      "source": [
        "def create_example_universes():\n",
        "    \"\"\"Create some example universes to demonstrate the system\"\"\"\n",
        "    examples = {}\n",
        "\n",
        "    print(\"Creating example universes...\")\n",
        "\n",
        "    # Fantasy universe\n",
        "    examples[\"Eldoria\"] = create_universe_from_name(\"Eldoria\", auto_populate=True)\n",
        "\n",
        "    # Sci-fi universe\n",
        "    examples[\"Nova Prism\"] = create_universe_from_name(\"Nova Prism\", auto_populate=True)\n",
        "\n",
        "    # Urban fantasy universe\n",
        "    examples[\"Hidden Hollows\"] = create_universe_from_name(\"Hidden Hollows\", auto_populate=True)\n",
        "\n",
        "    print(\"Example universes created!\")\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzHq3Nbev53q"
      },
      "source": [
        "### Main App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0t2Axk-v7Aj",
        "outputId": "b109a799-f3d7-4a71-c8af-cd9534a29d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced RAG-based Social Media Feed Generator\n",
            "=============================================\n",
            "This notebook demonstrates generating social media feeds based on fictional universes using knowledge graphs and RAG.\n",
            "The system can automatically expand a universe from just a name!\n",
            "\n",
            "Options:\n",
            "1. Create a universe from scratch with a name\n",
            "2. Use example universes (Eldoria, Nova Prism, Hidden Hollows)\n",
            "3. Use the interactive UI to create and explore universes\n"
          ]
        }
      ],
      "source": [
        "print(\"This notebook demonstrates generating social media feeds based on fictional universes using knowledge graphs and RAG.\")\n",
        "print(\"The system can automatically expand a universe from just a name!\")\n",
        "print(\"\\nOptions:\")\n",
        "print(\"1. Create a universe from scratch with a name\")\n",
        "print(\"2. Use example universes (Eldoria, Nova Prism, Hidden Hollows)\")\n",
        "print(\"3. Use the interactive UI to create and explore universes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "021973370d69439cb192413801c12922",
            "c18247a195374d7cbfa8ee5666f339ab",
            "ff0a2d9539f8429e9c3bd456bdd267b6",
            "b0a0d80e257246ac9547d54071e80cd7",
            "5d94659859e04ebd8da6904154582d7f",
            "51ad29ad3c5a45e9a68caf45ec884a07",
            "8c92dde8f7c1457caacd03ca053a9b1e",
            "180e72a8e2b9412da46bead3fe6324f7",
            "aa5cbd89071546b8b9e9c8be1074abe6",
            "79899b00dbc34a9abea8b229f9025d05",
            "c1a7fee45dee44a4b24e40012c422d55"
          ]
        },
        "id": "riIq6GGFv9c5",
        "outputId": "2bbda793-f650-40fb-b583-c93077337a9b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating example universes...\n",
            "Initializing LLM...\n",
            "Loading model - this might take a minute...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "021973370d69439cb192413801c12922",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "LLM initialized successfully!\n",
            "Expanding universe concept...\n"
          ]
        }
      ],
      "source": [
        "# Uncomment one of these to run the demo:\n",
        "#universe = create_universe_from_name(\"Star Wars during the Clone Wars\", auto_populate=True)\n",
        "#generate_demo_feed(universe, num_posts=8)\n",
        "#visualize_universe(universe)\n",
        "\n",
        "examples = create_example_universes()\n",
        "generate_demo_feed(examples[\"Eldoria\"], num_posts=8)\n",
        "visualize_universe(examples[\"Eldoria\"])\n",
        "\n",
        "# create_universe_ui()  # Interactive UI for creating and exploring universes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOEDzxtFxmgn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "021973370d69439cb192413801c12922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c18247a195374d7cbfa8ee5666f339ab",
              "IPY_MODEL_ff0a2d9539f8429e9c3bd456bdd267b6",
              "IPY_MODEL_b0a0d80e257246ac9547d54071e80cd7"
            ],
            "layout": "IPY_MODEL_5d94659859e04ebd8da6904154582d7f"
          }
        },
        "c18247a195374d7cbfa8ee5666f339ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ad29ad3c5a45e9a68caf45ec884a07",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c92dde8f7c1457caacd03ca053a9b1e",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "ff0a2d9539f8429e9c3bd456bdd267b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_180e72a8e2b9412da46bead3fe6324f7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa5cbd89071546b8b9e9c8be1074abe6",
            "value": 2
          }
        },
        "b0a0d80e257246ac9547d54071e80cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79899b00dbc34a9abea8b229f9025d05",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c1a7fee45dee44a4b24e40012c422d55",
            "value": "â€‡2/2â€‡[00:00&lt;00:00,â€‡â€‡5.78it/s]"
          }
        },
        "5d94659859e04ebd8da6904154582d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ad29ad3c5a45e9a68caf45ec884a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c92dde8f7c1457caacd03ca053a9b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "180e72a8e2b9412da46bead3fe6324f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5cbd89071546b8b9e9c8be1074abe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79899b00dbc34a9abea8b229f9025d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a7fee45dee44a4b24e40012c422d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}